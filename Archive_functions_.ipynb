{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_3d_plots(matrix_list, moments, cols=2, tick_interval=10):\n",
    "    num_plots = len(matrix_list)\n",
    "    rows = -(-num_plots // cols)  # Calculate rows needed (ceil division)\n",
    "    \n",
    "    fig = plt.figure(figsize=(cols * 8, rows * 6))\n",
    "    axes = [fig.add_subplot(rows, cols, i+1, projection='3d') for i in range(num_plots)]\n",
    "\n",
    "    for i, (matrix, moment) in enumerate(zip(matrix_list, moments)):\n",
    "        ax = axes[i]\n",
    "        matrix = matrix[:, ::-1]  # Reverse the matrix columns\n",
    "        matrix = matrix[::-1]  # Reverse the matrix rows for correct orientation\n",
    "        #y_labels = list(map(str, kwp_set))\n",
    "        y_labels = kwp_set[::-1]\n",
    "        #y_labels.reverse()\n",
    "\n",
    "        #x_labels = list(map(str, kw_set))\n",
    "        x_labels = kw_set[::-1]\n",
    "        #x_labels.reverse()\n",
    "\n",
    "        \n",
    "        # Create meshgrid for 3D plotting\n",
    "        X, Y = np.meshgrid(np.arange(matrix.shape[1]), np.arange(matrix.shape[0]))\n",
    "        Z = matrix\n",
    "\n",
    "        # Plot the 3D surface\n",
    "        ax.plot_surface(X, Y, Z, cmap='coolwarm')\n",
    "\n",
    "        # Customize color bar\n",
    "        cbar = fig.colorbar(ax.plot_surface(X, Y, Z, cmap='coolwarm'), ax=ax, shrink=0.5, aspect=5)\n",
    "        cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(f'{moment}', fontsize=18, weight='bold')\n",
    "        ax.set_xlabel(\"EV: charger kW values\", fontsize=14)\n",
    "        ax.set_ylabel(\"PV: kWp values\", fontsize=14)\n",
    "        #ax.set_zlabel(\"Value\", fontsize=14)\n",
    "\n",
    "        # Set x and y ticks every 'tick_interval' points\n",
    "        ax.set_xticks(np.arange(0, len(x_labels), tick_interval))\n",
    "        ax.set_xticklabels(x_labels[::tick_interval], fontsize=12)\n",
    "        ax.set_yticks(np.arange(0, len(y_labels), tick_interval))\n",
    "        ax.set_yticklabels(y_labels[::tick_interval], fontsize=12)\n",
    "        \n",
    "    # Hide unused subplots if any\n",
    "    for i in range(num_plots, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()  # Adjust spacing between subplots\n",
    "    plt.show()\n",
    "#plot_multiple_3d_plots([matrix_mean, matrix_std, matrix_skew, matrix_kurt], [\"Mean [kWh]\",\"Standard deviation [kWh]\",\"Skewness [/]\", \"Kurtosis [/]\"], cols=2,tick_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF of yearly consumed energy\n",
    "yearly_load = []\n",
    "for i, consumer in enumerate(all_consumer_profiles):\n",
    "    consumer_flat = consumer.values.flatten()\n",
    "    load = consumer_flat.sum()\n",
    "    yearly_load.append(load)\n",
    "    \n",
    "yearly_load_pandas = pd.Series(yearly_load)\n",
    "#ax = yearly_load_pandas.plot.density()\n",
    "plt.hist(yearly_load_pandas,'auto')\n",
    "ax = plt.gca()\n",
    "ax.set_title('Yearly consumed energy (over all consumers)')\n",
    "ax.set_xlabel('kWh')\n",
    "# plt.hist(yearly_load,bins='fd',density=True)\n",
    "# plt.axvline(x = 1000, color = 'g', label = 'Small')\n",
    "\n",
    "# Small and large consumer based on quantiles (middle values)\n",
    "yearly_load.sort()\n",
    "q25 = yearly_load_pandas.quantile(0.25)\n",
    "q75 = yearly_load_pandas.quantile(0.75)\n",
    "idx25 = bisect.bisect_left(yearly_load, q25)\n",
    "idx75 = bisect.bisect_left(yearly_load, q75)\n",
    "\n",
    "load25 = yearly_load[:25]\n",
    "load75 = yearly_load[75:]\n",
    "small = load25[round(len(load25)/2)]\n",
    "large = load75[round(len(load75)/2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chargingduration(chargingprofile):\n",
    "    nb_timeframes = np.count_nonzero(chargingprofile)\n",
    "    hours_charging = nb_timeframes/4\n",
    "    return hours_charging\n",
    "\n",
    "print('Total charging hours: ', chargingduration(chargingprofile1))\n",
    "print('Average hours per day: ', chargingduration(chargingprofile1)/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging_scenarios = pd.read_csv('./data/Charging_scenarios.csv')\n",
    "#display(charging_scenarios)\n",
    "arrival = charging_scenarios['arrival_time']\n",
    "departure = charging_scenarios['departure_time']\n",
    "chargetime = charging_scenarios['charge_time']\n",
    "\n",
    "ax = arrival.plot.density(label = 'Arrival time')\n",
    "ax.set_title('Arrival time (1 chargingprofile)')\n",
    "ax.set_xlabel('Hour')\n",
    "\n",
    "ax = chargetime.plot.density(label = 'Charge duration')\n",
    "ax.set_title('Arrival time & Charge duration (1 chargingprofile)')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer1_flat = pd.Series(consumer1.values.flatten())\n",
    "consumer2_flat = pd.Series(consumer2.values.flatten())\n",
    "consumer3_flat = pd.Series(consumer3.values.flatten())\n",
    "\n",
    "ax=consumer1_flat.plot.density(label = 'Small consumer')\n",
    "consumer2_flat.plot.density(label = 'Medium consumer')\n",
    "consumer3_flat.plot.density(label = 'Large consumer')\n",
    "ax.set_title('15 min consumption (over 1 year)')\n",
    "ax.set_xlabel('kWh')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer1_flat = pd.Series(consumer1.values.flatten())\n",
    "solargen_flat = (charging_profiles_dict[7].values.flatten())\n",
    "kw = 0\n",
    "kwp = 7\n",
    "net_load = pd.Series((consumer_flat*4 + solargen_flat)/4)\n",
    "\n",
    "ax=consumer1_flat.plot.density(label = 'Small consumer')\n",
    "# consumer2_flat.plot.density(label = 'Medium consumer')\n",
    "# consumer3_flat.plot.density(label = 'Large consumer')\n",
    "net_load.plot.density()\n",
    "ax.set_title('15 min consumption (over 1 year)')\n",
    "ax.set_xlabel('kWh')\n",
    "ax.legend()\n",
    "\n",
    "print(consumer1_flat.std())\n",
    "print(net_load.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_whole_profile(consumer):\n",
    "    # kwp_set = np.linspace(0, 10, 100) # From 0 to 10 with 100 steps\n",
    "    # kw_set = np.linspace(0, 23, 100)\n",
    "    step = 0.1\n",
    "    kwp_set = np.arange(0, 7+step, step)\n",
    "    kw_set = np.arange(0, 7+step, step)\n",
    "    kw_set = [round(elem, 1) for elem in kw_set]\n",
    "    kwp_set = [round(elem, 1) for elem in kwp_set]\n",
    "\n",
    "    nb_kwp = len(kwp_set)\n",
    "    nb_kw = len(kw_set)\n",
    "    # index =  ['Min', 'Max', 'Mean', 'Std', 'Skew', 'Kurt', 'Var', 'Load', 'q5', 'q95', 'Entropy', 'KL', 'TVD', 'Wasserstein']\n",
    "    # metrics = pd.DataFrame(index=index, columns=['Matrix'], dtype=object)\n",
    "\n",
    "    matrix_min = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_max = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_mean = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_std = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_skew = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_kurt = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_var = np.zeros((nb_kwp, nb_kw))\n",
    "\n",
    "    matrix_load = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_q5 = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_q95 = np.zeros((nb_kwp, nb_kw))\n",
    "\n",
    "    matrix_entropy = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_KL = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_total_distance = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_wasserstein_distance = np.zeros((nb_kwp, nb_kw))\n",
    "\n",
    "    consumer_flat = consumer.values.flatten()\n",
    "    solargen_flat = solargen.values.flatten()\n",
    "    #chargingprofile1_flat = chargingprofile1.values.flatten()\n",
    "    \n",
    "    for i, kwp in enumerate(kwp_set):\n",
    "        print('iteration :', i, ' of ', nb_kwp)\n",
    "        for j, kw in enumerate(kw_set):\n",
    "            if kw == 0:\n",
    "                charging_profile = charging_profiles_dict[0.1]\n",
    "                chargingprofile_flat = charging_profile.values.flatten()\n",
    "            else: \n",
    "                charging_profile = charging_profiles_dict[kw]\n",
    "                chargingprofile_flat = charging_profile.values.flatten()\n",
    "            chargingprofile_flat[np.isnan(chargingprofile_flat)] = 0\n",
    "\n",
    "            #chargingprofile_flat = chargingprofile1.values.flatten()\n",
    "            net_load = consumer_flat*4 - kwp*solargen_flat + chargingprofile_flat\n",
    "            net_load = net_load/4\n",
    "            matrix_min[i,j] = net_load.min()\n",
    "            matrix_max[i,j] = net_load.max()\n",
    "            matrix_mean[i,j] = net_load.mean()\n",
    "            matrix_std[i,j] = net_load.std()\n",
    "            matrix_skew[i,j] = pd.Series(net_load).skew()\n",
    "            matrix_kurt[i,j] = pd.Series(net_load).kurt()\n",
    "            matrix_var[i,j] = pd.Series(net_load).var()\n",
    "\n",
    "            # matrix_skew[kwp,kw] = skew(net_load)\n",
    "            # matrix_kurt[kwp,kw] = kurtosis(net_load)\n",
    "\n",
    "            matrix_load[i,j] = net_load.sum()\n",
    "            matrix_q5[i,j] = pd.Series(net_load).quantile(.05)\n",
    "            matrix_q95[i,j] = pd.Series(net_load).quantile(.95)\n",
    "\n",
    "            # #Compute common bin width\n",
    "            # hist_base, bin_edges_base = np.histogram(consumer_flat,bins='auto',density=False)\n",
    "            # bin_width = bin_edges_base[1] - bin_edges_base[0]\n",
    "            # adjusted_min = consumer_flat.min()\n",
    "            # while adjusted_min > net_load.min():\n",
    "            #     adjusted_min -= bin_width\n",
    "            # adjusted_max = consumer_flat.max()\n",
    "            # while adjusted_max < net_load.max():\n",
    "            #     adjusted_max += bin_width\n",
    "\n",
    "            # bin_edges_net_load = np.arange(adjusted_min, adjusted_max + bin_width, bin_width)\n",
    "            # bin_edges_net_load = [ round(elem, 5) for elem in bin_edges_net_load ]\n",
    "            # bin_edges_base = [ round(elem, 5) for elem in bin_edges_base ]\n",
    "\n",
    "            # hist_net_load, _ = np.histogram(net_load,bins=bin_edges_net_load,density=False)\n",
    "\n",
    "            # # Compute histograms\n",
    "\n",
    "            # # hist_net_load, bin_edges_net = np.histogram(net_load,bins=bin_edges_net_load,density=True)\n",
    "            # # hist_base, bin_edges_base = np.histogram(consumer1,bins=bins,range=(global_min,global_max),density=True)\n",
    "            \n",
    "            # # Turn hist into 'PDF' (counts to probabilities)\n",
    "            # hist_net_load = hist_net_load/hist_net_load.sum()\n",
    "            # hist_base = hist_base/hist_base.sum()\n",
    "            \n",
    "            # #S_max = np.log2(nb_bins)\n",
    "            # matrix_entropy[i,j] = entropy(hist_net_load,base=2) # /S_max\n",
    "            # epsilon = 1e-10\n",
    "            # common_bin_edges = np.union1d(bin_edges_base, bin_edges_net_load)\n",
    "            # hist_base, bin_edges_base = np.histogram(consumer_flat,bins=common_bin_edges,density=False)\n",
    "            # hist_net_load, bin_edges_net_load = np.histogram(net_load,bins=common_bin_edges,density=False)\n",
    "\n",
    "            # hist_net_load = hist_net_load/hist_net_load.sum()\n",
    "            # hist_base = hist_base/hist_base.sum()\n",
    "            \n",
    "            # hist_base = hist_base+epsilon\n",
    "            # hist_net_load = hist_net_load+epsilon\n",
    "\n",
    "            # matrix_KL[i,j] = entropy(pk=hist_base, qk=hist_net_load, base=2)\n",
    "\n",
    "            # #dist = np.linalg.norm(np.array(hist_base) - np.array(hist_net_load))\n",
    "            # #dist = dist/2\n",
    "            # tvd = 0.5 * np.sum(np.abs(hist_base - hist_net_load))\n",
    "            # matrix_total_distance[i,j] = tvd\n",
    "\n",
    "            # midpoints_net = (bin_edges_net_load[:-1] + bin_edges_net_load[1:]) / 2\n",
    "            # midpoints_base = (bin_edges_base[:-1] + bin_edges_base[1:]) / 2\n",
    "            # # midpoints = (common_bin_edges[:-1] + common_bin_edges[1:]) / 2\n",
    "            # # wasserstein_dist = wasserstein_distance(midpoints, midpoints, u_weights=hist_base, v_weights=hist_net_load)\n",
    "            # wasserstein_dist = wasserstein_distance(midpoints_base, midpoints_net, u_weights=hist_base, v_weights=hist_net_load)\n",
    "            \n",
    "            # matrix_wasserstein_distance[i,j] = wasserstein_dist\n",
    "       \n",
    "    # metrics.loc['Min', 'Matrix'] = matrix_min\n",
    "    # metrics.loc['Max', 'Matrix'] = matrix_max\n",
    "    # metrics.loc['Mean', 'Matrix'] = matrix_mean \n",
    "    # metrics.loc['Std', 'Matrix'] = matrix_std \n",
    "    # metrics.loc['Skew', 'Matrix'] = matrix_skew \n",
    "    # metrics.loc['Kurt', 'Matrix'] = matrix_kurt \n",
    "    # metrics.loc['Var', 'Matrix'] = matrix_var\n",
    "    # metrics.loc['Load', 'Matrix'] = matrix_load \n",
    "    # metrics.loc['q5', 'Matrix'] = matrix_q5 \n",
    "    # metrics.loc['q95', 'Matrix'] = matrix_q95 \n",
    "    # metrics.loc['Entropy', 'Matrix'] = matrix_entropy \n",
    "    # metrics.loc['KL', 'Matrix'] = matrix_KL \n",
    "    # metrics.loc['TVD', 'Matrix'] = matrix_total_distance \n",
    "    # metrics.loc['Wasserstein', 'Matrix'] = matrix_wasserstein_distance \n",
    "    metrics = {}\n",
    "\n",
    "    metrics[\"Min\"] = matrix_min\n",
    "    metrics['Max'] = matrix_max\n",
    "    metrics['Mean'] = matrix_mean \n",
    "    metrics['Std'] = matrix_std \n",
    "    metrics['Skew'] = matrix_skew \n",
    "    metrics['Kurt'] = matrix_kurt \n",
    "    metrics['Var'] = matrix_var\n",
    "    metrics['Load'] = matrix_load \n",
    "    metrics['q5'] = matrix_q5 \n",
    "    metrics['q95'] = matrix_q95\n",
    "     \n",
    "    # metrics['Entropy'] = matrix_entropy \n",
    "    # metrics['KL'] = matrix_KL \n",
    "    # metrics['TVD'] = matrix_total_distance \n",
    "    # metrics['Wasserstein'] = matrix_wasserstein_distance \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CONSUMER1 started...')\n",
    "metrics_consumer_1 = metrics_whole_profile(consumer1)\n",
    "print('CONSUMER1 done!')\n",
    "\n",
    "print('CONSUMER2 started...')\n",
    "metrics_consumer_2 = metrics_whole_profile(consumer2)\n",
    "print('CONSUMER2 done!')\n",
    "\n",
    "print('CONSUMER3 started...')\n",
    "metrics_consumer_3 = metrics_whole_profile(consumer3)\n",
    "print('CONSUMER3 done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(consumer):\n",
    "    step = 0.1\n",
    "    kwp_set = np.arange(0, 7+step, step)\n",
    "    kw_set = np.arange(0, 7+step, step)\n",
    "    kw_set = [round(elem, 1) for elem in kw_set]\n",
    "    kwp_set = [round(elem, 1) for elem in kwp_set]\n",
    "\n",
    "    nb_kwp = len(kwp_set)\n",
    "    nb_kw = len(kw_set)\n",
    "\n",
    "    # matrix_min = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_max = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_mean = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_std = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_skew = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_kurt = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_var = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_cov = np.zeros((nb_kwp, nb_kw))\n",
    "\n",
    "    # matrix_load = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_q5 = np.zeros((nb_kwp, nb_kw))\n",
    "    # matrix_q95 = np.zeros((nb_kwp, nb_kw))\n",
    "\n",
    "    matrix_entropy = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_KL = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_total_distance = np.zeros((nb_kwp, nb_kw))\n",
    "    matrix_wasserstein_distance = np.zeros((nb_kwp, nb_kw))\n",
    "\n",
    "    # Precompute histograms for consumer[day] once to avoid recomputation\n",
    "    consumer_histograms = {}\n",
    "    consumer_bin_edges = {}\n",
    "\n",
    "    for day in range(1, 366):\n",
    "        hist_base, bin_edges_base = np.histogram(consumer[day], bins='fd', density=True)\n",
    "        consumer_histograms[day] = hist_base\n",
    "        consumer_bin_edges[day] = bin_edges_base\n",
    "\n",
    "    for i, kwp in enumerate(kwp_set):\n",
    "        print('iteration :', i, ' of ', nb_kwp)\n",
    "        for j, kw in enumerate(kw_set):\n",
    "            print(j, ' kw')\n",
    "            chargingprofile = charging_profiles_dict[kw]\n",
    "            chargingprofile = chargingprofile.fillna(0)\n",
    "            net_load = consumer*4 - kwp*solargen + chargingprofile\n",
    "            net_load = net_load/4\n",
    "\n",
    "            # matrix_min[i,j] = net_load.min().min()\n",
    "            # matrix_max[i,j] = net_load.max().max()\n",
    "            # matrix_mean[i,j] = net_load.mean().mean()\n",
    "            # matrix_load[i,j] = net_load.sum().sum()\n",
    "            # matrix_q5[i,j] = pd.Series(net_load.values.flatten()).quantile(.05)\n",
    "            # matrix_q95[i,j] = pd.Series(net_load.values.flatten()).quantile(.95)\n",
    "        \n",
    "            # matrix_std[i,j] = (net_load.std(axis=0,ddof=0)).sum()/365\n",
    "            # matrix_skew[i,j] = (net_load.skew(axis=0)).sum()/365\n",
    "            # matrix_kurt[i,j] = (net_load.kurt(axis=0)).sum()/365\n",
    "            # matrix_var[i,j] = (net_load.var(axis=0)).sum()/365\n",
    "            # matrix_cov[i,j] = (net_load.std(axis=0,ddof=0)/net_load.mean(axis=0)).sum()/365\n",
    "\n",
    "            #Compute common bin width\n",
    "            # shannon_over_days = [] # Take mean of this\n",
    "            # kld_over_days = []\n",
    "            # tvd_over_days = []\n",
    "            # wasserstein_over_days = []\n",
    "            shannon_over_days = np.zeros(365)\n",
    "            kld_over_days = np.zeros(365)\n",
    "            tvd_over_days = np.zeros(365)\n",
    "            wasserstein_over_days = np.zeros(365)\n",
    "            for day in range(1,366):\n",
    "                net_load_day = net_load[day]\n",
    "                #hist_base, bin_edges_base = np.histogram(consumer[day],bins='fd',density=True)\n",
    "                hist_base = consumer_histograms[day]\n",
    "                bin_edges = consumer_bin_edges[day]\n",
    "\n",
    "                bin_width = bin_edges_base[1] - bin_edges_base[0]\n",
    "                adjusted_min = consumer[day].min()\n",
    "                while adjusted_min > net_load_day.min():\n",
    "                    adjusted_min -= bin_width\n",
    "                adjusted_max = consumer[day].max()\n",
    "                while adjusted_max < net_load_day.max():\n",
    "                    adjusted_max += bin_width\n",
    "\n",
    "                bin_edges_net_load_day = np.arange(adjusted_min, adjusted_max + bin_width, bin_width)\n",
    "                bin_edges_net_load_day = [ round(elem, 5) for elem in bin_edges_net_load_day ]\n",
    "                bin_edges_base = [ round(elem, 5) for elem in bin_edges_base ]\n",
    "                hist_net_load_day, _ = np.histogram(net_load_day,bins=bin_edges_net_load_day,density=True)\n",
    "\n",
    "                # Compute histograms                \n",
    "                # Turn hist into 'PDF' (counts to probabilities)\n",
    "                # hist_net_load_day = hist_net_load_day/hist_net_load_day.sum()\n",
    "                # hist_base = hist_base/hist_base.sum()\n",
    "                \n",
    "                #S_max = np.log2(nb_bins)\n",
    "                # matrix_entropy[i,j] = entropy(hist_net_load_day,base=2) # /S_max\n",
    "                shannon_over_days[day-1] = entropy(hist_net_load_day,base=2)\n",
    "\n",
    "                ### KLD\n",
    "                epsilon = 1e-10\n",
    "                common_bin_edges = np.union1d(bin_edges_base, bin_edges_net_load_day)\n",
    "                hist_base, bin_edges_base = np.histogram(consumer[day],bins=common_bin_edges,density=True)\n",
    "                hist_net_load_day, bin_edges_net_load_day = np.histogram(net_load_day,bins=common_bin_edges,density=True)\n",
    "\n",
    "                # hist_net_load_day = hist_net_load_day/hist_net_load_day.sum()\n",
    "                # hist_base = hist_base/hist_base.sum()\n",
    "                \n",
    "                hist_base = hist_base+epsilon\n",
    "                hist_net_load_day = hist_net_load_day+epsilon\n",
    "\n",
    "                kld_over_days[day-1] = entropy(pk=hist_base, qk=hist_net_load_day, base=2)\n",
    "\n",
    "                ### TVD\n",
    "                #dist = np.linalg.norm(np.array(hist_base) - np.array(hist_net_load_day))\n",
    "                #dist = dist/2\n",
    "                tvd = 0.5 * np.sum(np.abs(hist_base - hist_net_load_day))\n",
    "                tvd_over_days[day-1] = tvd\n",
    "\n",
    "                ### Wasserstein\n",
    "                midpoints_net = (bin_edges_net_load_day[:-1] + bin_edges_net_load_day[1:]) / 2\n",
    "                midpoints_base = (bin_edges_base[:-1] + bin_edges_base[1:]) / 2\n",
    "                # midpoints = (common_bin_edges[:-1] + common_bin_edges[1:]) / 2\n",
    "                # wasserstein_dist = wasserstein_distance(midpoints, midpoints, u_weights=hist_base, v_weights=hist_net_load)\n",
    "                wasserstein_dist = wasserstein_distance(midpoints_base, midpoints_net, u_weights=hist_base, v_weights=hist_net_load_day)\n",
    "                wasserstein_over_days[day-1] = wasserstein_dist\n",
    "\n",
    "            matrix_entropy[i,j] = np.mean(shannon_over_days)\n",
    "            matrix_KL[i,j] = np.mean(kld_over_days)\n",
    "            matrix_total_distance[i,j] = np.mean(tvd_over_days)\n",
    "            matrix_wasserstein_distance[i,j] = np.mean(wasserstein_over_days)\n",
    "\n",
    "\n",
    "    metrics = {}\n",
    "    # metrics[\"Min\"] = matrix_min\n",
    "    # metrics['Max'] = matrix_max\n",
    "    # metrics['Mean'] = matrix_mean \n",
    "    # metrics['Std'] = matrix_std \n",
    "    # metrics['Skew'] = matrix_skew \n",
    "    # metrics['Kurt'] = matrix_kurt \n",
    "    # metrics['Var'] = matrix_var\n",
    "    # metrics['Load'] = matrix_load \n",
    "    # metrics['q5'] = matrix_q5 \n",
    "    # metrics['q95'] = matrix_q95\n",
    "    # metrics['cov'] = matrix_cov\n",
    "     \n",
    "    metrics['Entropy'] = matrix_entropy \n",
    "    metrics['KL'] = matrix_KL \n",
    "    metrics['TVD'] = matrix_total_distance \n",
    "    metrics['Wasserstein'] = matrix_wasserstein_distance \n",
    "    return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THESIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
